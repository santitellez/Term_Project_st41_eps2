{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pixel_By_Pixel-checkpoint.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Hfo9t3I956Xv",
        "colab_type": "code",
        "outputId": "d32fed30-39cf-4f60-8824-701ea57359c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import itertools as it\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from PIL import Image as ig\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "\n",
        "#from utils import *\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense, MaxPooling2D, Conv2D, Activation, UpSampling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VtSrzQW-5_-x",
        "colab_type": "code",
        "outputId": "8f60653d-335c-4a32-afd2-97381c426849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/santitellez/Term_Project_st41_eps2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Term_Project_st41_eps2'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 22369 (delta 26), reused 41 (delta 14), pack-reused 22315\u001b[K\n",
            "Receiving objects: 100% (22369/22369), 629.77 MiB | 33.15 MiB/s, done.\n",
            "Resolving deltas: 100% (1176/1176), done.\n",
            "Checking out files: 100% (23991/23991), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fWIxYjFl6ZbS",
        "colab_type": "code",
        "outputId": "c65e535b-379e-4534-b94b-b431d83a4447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  Term_Project_st41_eps2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qjCz5zLj56X2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Functions\n",
        "\n",
        "BatchSize = 10\n",
        "\n",
        "def create_submission(csv_name, predictions, image_ids):\n",
        "    \"\"\"\n",
        "    csv_name -> string for csv ('XXXXXXX.csv')\n",
        "    predictions -> numpyarray of size (num_examples, height, width)\n",
        "                In this case (num_examples, 512, 512)\n",
        "    image_ids -> numpyarray or list of size (num_examples,)\n",
        "    \n",
        "    predictions[i] should be the prediciton of road for image_id[i]\n",
        "    \"\"\"\n",
        "    sub = pd.DataFrame()\n",
        "    sub['ImageId'] = image_ids\n",
        "    encodings = []\n",
        "    num_images = len(image_ids)\n",
        "    for i in range(num_images):\n",
        "        if (i+1) % (num_images//10) == 0:\n",
        "            print(i, num_images)\n",
        "        encodings.append(rle_encoding(predictions[i]))\n",
        "        \n",
        "    sub['EncodedPixels'] = encodings\n",
        "    sub['Height'] = [512]*num_images\n",
        "    sub['Width'] = [512]*num_images\n",
        "    sub.to_csv(csv_name, index=False)\n",
        "\n",
        "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
        "def rle_encoding(x):\n",
        "    \"\"\"\n",
        "    x = numpyarray of size (height, width) representing the mask of an image\n",
        "    if x[i,j] == 0:\n",
        "        image[i,j] is not a road pixel\n",
        "    if x[i,j] != 0:\n",
        "        image[i,j] is a road pixel\n",
        "    \"\"\"\n",
        "    dots = np.where(x.T.flatten() != 0)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): \n",
        "            run_lengths.extend((b+1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "def get_img_id(img_path):\n",
        "    \n",
        "    img_basename = os.path.basename(img_path)\n",
        "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
        "    return img_id\n",
        "\n",
        "def image_gen(img_paths, img_size=(512, 512)):\n",
        "\n",
        "    for img_path in img_paths:\n",
        "        \n",
        "        img_id = get_img_id(img_path)\n",
        "        mask_path = os.path.join('Term_Project_st41_eps2/comp-540-spring-2019/train', img_id + '_msk.png')\n",
        "        \n",
        "        img = imread(img_path) / 255.\n",
        "        mask = rgb2gray(imread(mask_path))\n",
        "        \n",
        "        img = resize(img, img_size, preserve_range=True)\n",
        "        mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
        "        mask = (mask >= 0.5).astype(float)\n",
        "        \n",
        "        yield img, mask\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    \n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    \n",
        "    return score\n",
        "\n",
        "def image_batch_generator(img_paths, batchsize = BatchSize):\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        ig = image_gen(img_paths)\n",
        "        batch_img, batch_mask = [], []\n",
        "        \n",
        "        for img, mask in ig:\n",
        "\n",
        "            batch_img.append(img)\n",
        "            batch_mask.append(mask)\n",
        "\n",
        "            if len(batch_img) == batchsize:\n",
        "                \n",
        "                yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
        "                batch_img, batch_mask = [], []\n",
        "        \n",
        "        if len(batch_img) != 0:\n",
        "            yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
        "            batch_img, batch_mask = [], []\n",
        "            \n",
        "def image_batch_generator_model1(img_paths, batchsize = BatchSize):\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        ig = image_gen(img_paths)\n",
        "        batch_img, batch_mask = [], []\n",
        "        \n",
        "        for img, mask in ig:\n",
        "\n",
        "            batch_img.append(img)\n",
        "            batch_mask.append((np.sum(mask) > 0) * 1)\n",
        "\n",
        "            if len(batch_img) == batchsize:\n",
        "                \n",
        "                yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
        "                batch_img, batch_mask = [], []\n",
        "        \n",
        "        if len(batch_img) != 0:\n",
        "            yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
        "            batch_img, batch_mask = [], []\n",
        "\n",
        "def calc_steps(data_len, batchsize):\n",
        "    \n",
        "    return (data_len + batchsize - 1) // batchsize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I-EiFCNA56X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Model Pipeline Parameters\n",
        "\n",
        "ImgPaths = glob.glob(\"Term_Project_st41_eps2/comp-540-spring-2019/train/*.jpg\")\n",
        "ImgNums = [re.findall(r'/(\\d+)', path)[0] for path in ImgPaths]\n",
        "\n",
        "M = len(glob.glob(\"Term_Project_st41_eps2/comp-540-spring-2019/train/*.jpg\")) # Number of training images\n",
        "H = 512 # Image height\n",
        "W = 512 # Image width\n",
        "C = 3 # Channels R, G, B\n",
        "\n",
        "Pt = .8 # Train proportion\n",
        "Pv = .2 # Validation proportion\n",
        "P1 = .25 # Proportion of data used in Model 1\n",
        "P2 = .5 # Proportion of data used in Model 2\n",
        "P3 = 1 - P1 - P2 # Proportion of data used in Model 3\n",
        "\n",
        "# Subsetting images for training and validation\n",
        "\n",
        "random.seed(1)\n",
        "RandomOrder = np.random.choice(ImgNums, M, replace = False)\n",
        "\n",
        "ImgNums1 = RandomOrder[:int(M * P1)] # Model 1 images\n",
        "ImgNums2 = RandomOrder[int(M * P1):int(M * (P1 + P2))] # Model 2 images\n",
        "ImgNums3 = RandomOrder[int(M * (P1 + P2)):] # Model 3 images\n",
        "\n",
        "BatchSize = 10\n",
        "\n",
        "smooth = 1e-9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E1yWCvhu56YA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHemmJU956YE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Feature engineering Model 1\n",
        "\n",
        "def Model1FeatureEngineering(imgnums, train_or_val = \"train\"):\n",
        "    Data = []\n",
        "\n",
        "    for num in imgnums:\n",
        "        img = ig.open(\"comp-540-spring-2019/\" + train_or_val + \"/\" + num + \"_sat.jpg\")\n",
        "        if train_or_val == \"train\":\n",
        "            msk = ig.open(\"comp-540-spring-2019/\" + train_or_val + \"/\" + num + \"_msk.png\")\n",
        "        img_mat = np.array(img.getdata())\n",
        "        img_avg = np.mean(img_mat, axis = 0)\n",
        "        img_med = np.median(img_mat, axis = 0)\n",
        "        img_var = np.var(img_mat, axis = 0)\n",
        "        img_min = np.amin(img_mat, axis = 0)\n",
        "        img_max = np.amax(img_mat, axis = 0)\n",
        "        img_ran = np.ptp(img_mat, axis = 0)\n",
        "        img_25q = np.percentile(img_mat, axis = 0, q = 25)\n",
        "        img_75q = np.percentile(img_mat, axis = 0, q = 75)\n",
        "        if train_or_val == \"train\":\n",
        "            y = [(np.sum(np.array(msk.getdata())) > 0) * 1]\n",
        "\n",
        "            img_data = np.concatenate((img_avg, img_med, img_var, img_min, img_max, img_ran, img_25q, img_75q, y))\n",
        "        if train_or_val == \"val\":\n",
        "            img_data = np.concatenate((img_avg, img_med, img_var, img_min, img_max, img_ran, img_25q, img_75q))\n",
        "        Data.append(img_data)\n",
        "\n",
        "    Data = np.array(Data)\n",
        "    return(Data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4aF9O5I56YI",
        "colab_type": "code",
        "outputId": "e572973f-12d5-4d8d-9552-faea82ab5b01",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Model for predicting whether image has any roads\n",
        "\n",
        "Data = Model1FeatureEngineering(ImgNums1, \"train\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(Data[:, :(Data.shape[1] - 1)], Data[:, (Data.shape[1] - 1)], train_size = Pt)\n",
        "\n",
        "ntrees = [50]\n",
        "mtrys = [2]\n",
        "max_depth = [35]\n",
        "\n",
        "results = {}\n",
        "best_val_acc = 0\n",
        "\n",
        "for nt in ntrees:\n",
        "    for mt in mtrys:\n",
        "        for md in max_depth:\n",
        "            any_roads_model = RandomForestClassifier(n_estimators = nt, max_depth = md, min_samples_split = mt)\n",
        "            any_roads_model_fit = any_roads_model.fit(X_train, y_train)\n",
        "            \n",
        "            y_pred = np.round(any_roads_model.predict(X_val))\n",
        "            y_pred = np.round(y_pred)\n",
        "            val_acc = np.sum(y_pred == y_val) / y_val.shape[0]\n",
        "            \n",
        "            results[(nt, mt, md)] = val_acc\n",
        "            \n",
        "            if val_acc > best_val_acc:\n",
        "                best_model = any_roads_model\n",
        "                best_val_acc = val_acc\n",
        "\n",
        "y_pred = np.round(best_model.predict(X_val))\n",
        "\n",
        "conf_mat = confusion_matrix(y_val, y_pred)\n",
        "print(conf_mat)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 29  58]\n",
            " [ 11 447]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.72      0.33      0.46        87\n",
            "         1.0       0.89      0.98      0.93       458\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       545\n",
            "   macro avg       0.81      0.65      0.69       545\n",
            "weighted avg       0.86      0.87      0.85       545\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O7o8lsOG56YT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Images for convolutional net\n",
        "\n",
        "def images_conv(img_nums):\n",
        "    \n",
        "    #X_train = []\n",
        "    y_train = []\n",
        "    \n",
        "    for i in list(img_nums):\n",
        "        \n",
        "        #img = ig.open(\"comp-540-spring-2019/train/\" + i + \"_sat.jpg\")\n",
        "        msk = ig.open(\"Term_Project_st41_eps2/comp-540-spring-2019/train/\" + i + \"_msk.png\")\n",
        "        #img_mat = np.array(img.getdata()).reshape((512, 512, 3))\n",
        "        y = [pix[0] for pix in list(msk.getdata())]\n",
        "        \n",
        "        #X_train.append(img_mat)\n",
        "        y_train.append((sum(y) > 0) * 1)\n",
        "        \n",
        "    #return np.array(X_train), y_train\n",
        "    return y_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAWgGN8i56YW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Convolutional net for predicting whether image has any roads\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(8, (4, 4), input_shape = (H, W, C)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, (4, 4)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "\n",
        "model.add(Conv2D(16, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dense(200))\n",
        "model.add(Dropout(.75))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rKm-dEDO56Yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### All images at once\n",
        "\n",
        "X_train, y_train = images_conv(ImgNums1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = Pv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tpkqumfK56Yk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ax6akNsf56Yx",
        "colab_type": "code",
        "outputId": "113c0dfb-cb71-4fc4-d1e3-d2071c6c1508",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Train first model\n",
        "\n",
        "BatchSize = 20\n",
        "epochs = 5\n",
        "earlystopper = EarlyStopping(patience = 2, verbose = 1)\n",
        "checkpointer = ModelCheckpoint('Model1.h5', verbose = 1, save_best_only = True)\n",
        "\n",
        "ImgNums1_paths = list(it.compress(ImgPaths, list(np.isin(np.array(ImgNums), ImgNums1))))\n",
        "ImgNums1_paths_train, ImgNums1_paths_val = train_test_split(ImgNums1_paths, test_size = Pv)\n",
        "ImgNums1_gen_train = image_batch_generator_model1(ImgNums1_paths_train, batchsize = BatchSize)\n",
        "ImgNums1_gen_val = image_batch_generator_model1(ImgNums1_paths_val, batchsize = BatchSize)\n",
        "\n",
        "model.fit_generator(ImgNums1_gen_train,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = ImgNums1_gen_val,\n",
        "                    steps_per_epoch = calc_steps(len(ImgNums1_paths_train), BatchSize),\n",
        "                    validation_steps = calc_steps(len(ImgNums1_paths_val), BatchSize),\n",
        "                    callbacks = [earlystopper, checkpointer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 23/109 [=====>........................] - ETA: 8:12 - loss: 0.6264 - acc: 0.8152"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4d47e4bb7f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImgNums1_paths_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImgNums1_paths_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     callbacks = [earlystopper, checkpointer])\n\u001b[0m",
            "\u001b[0;32m/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "u-2x4Cv556Y0",
        "colab_type": "code",
        "outputId": "0c4cef30-f5ca-46b1-c27d-85cb339cc86a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 512, 512, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "q0P8YEVZ56Y4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Best convolutional Model 1\n",
        "\n",
        "best_conv1 = load_model(\"Model1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QgvnlY4Q56Y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Save best Model 1\n",
        "\n",
        "best_model1 = joblib.dump(best_model, \"Model1.sav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CW9wduhA56ZA",
        "colab_type": "code",
        "outputId": "f52bb5ac-3618-4ffd-f3fd-c912f7820c6c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Model 1 feature engineering for Model 2\n",
        "\n",
        "ImgNums23 = np.concatenate((ImgNums2, ImgNums3))\n",
        "Data =  Model1FeatureEngineering(ImgNums23, \"train\")\n",
        "\n",
        "y_actual = Data[:, (Data.shape[1] - 1)]\n",
        "Data = Data[:, :(Data.shape[1] - 1)]\n",
        "\n",
        "y_pred = np.round(best_model.predict(Data))\n",
        "\n",
        "conf_mat = confusion_matrix(y_actual, y_pred)\n",
        "print(conf_mat)\n",
        "print(classification_report(y_actual, y_pred))\n",
        "\n",
        "ImgNumsWithRoads = ImgNums23[(y_pred == 1)]\n",
        "ImgNumsWithoutRoads = ImgNums23[(y_pred != 1)]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 524  825]\n",
            " [ 277 6547]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.39      0.49      1349\n",
            "         1.0       0.89      0.96      0.92      6824\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      8173\n",
            "   macro avg       0.77      0.67      0.70      8173\n",
            "weighted avg       0.85      0.87      0.85      8173\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w7xwqN-o56ZR",
        "colab_type": "code",
        "outputId": "3311faa7-f450-4ae1-e893-7a912ecaef0a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Predicting convolutional net to determine if remaining images have roads\n",
        "\n",
        "BatchSize = 1\n",
        "\n",
        "ImgNums23 = np.concatenate((ImgNums2, ImgNums3))\n",
        "\n",
        "ImgNums23_paths = list(it.compress(ImgPaths, list(np.isin(np.array(ImgNums), ImgNums23))))\n",
        "ImgNums23_gen = image_batch_generator_model1(ImgNums23_paths, batchsize = BatchSize)\n",
        "\n",
        "y_pred = np.squeeze(best_conv1.predict_generator(ImgNums23_gen, steps = len(ImgNums23_paths))).astype(int)\n",
        "y_actual = np.array(images_conv(ImgNums23))\n",
        "\n",
        "conf_mat = confusion_matrix(y_actual, y_pred)\n",
        "print(conf_mat)\n",
        "print(classification_report(y_actual, y_pred))\n",
        "\n",
        "ImgNumsWithRoads = ImgNums23[(y_pred == 1)]\n",
        "ImgNumsWithoutRoads = ImgNums23[(y_pred != 1)]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1365    1]\n",
            " [6793   14]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      1.00      0.29      1366\n",
            "           1       0.93      0.00      0.00      6807\n",
            "\n",
            "   micro avg       0.17      0.17      0.17      8173\n",
            "   macro avg       0.55      0.50      0.15      8173\n",
            "weighted avg       0.81      0.17      0.05      8173\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1UFsALLB56ZW",
        "colab_type": "code",
        "outputId": "75fd1db3-01b9-4a43-edc1-c6d4f9a46bef",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3aaf935e6aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Dc8-Wtdv56Za",
        "colab_type": "code",
        "outputId": "9e11c5ee-0407-4e27-8cdd-6d6b2f8fd729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1632
        }
      },
      "cell_type": "code",
      "source": [
        "### Building U-Net for images with roads\n",
        "# Generally, decrease (x,y) by factor 2 => Increase (z) by factor 2\n",
        "\n",
        "inputs = Input((H, W, C))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "n = 1 # can use this as a performance complexity lever\n",
        "\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "c1 = Dropout(0.1) (c1)\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "c2 = Dropout(0.1) (c2)\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "c5 = Dropout(0.3) (c5)\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "c8 = Dropout(0.1) (c8)\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "c9 = Dropout(0.1) (c9)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "Model2 = Model(inputs=[inputs], outputs=[outputs])\n",
        "Model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
        "Model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 512, 512, 3)  0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 512, 512, 16) 448         lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 512, 512, 16) 0           conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 512, 512, 16) 2320        dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, 256, 256, 16) 0           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 256, 256, 32) 4640        max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 256, 256, 32) 0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 256, 256, 32) 9248        dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, 128, 128, 32) 0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 128, 128, 64) 18496       max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 128, 128, 64) 0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 128, 128, 64) 36928       dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 64, 64, 128)  73856       max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 64, 64, 128)  0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 64, 64, 128)  147584      dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 32, 32, 256)  295168      max_pooling2d_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 32, 32, 256)  0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 32, 32, 256)  590080      dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 128)  131200      conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_5[0][0]         \n",
            "                                                                 conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 64, 64, 128)  295040      concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 64, 64, 128)  0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 64, 64, 128)  147584      dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 64) 32832       conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_6[0][0]         \n",
            "                                                                 conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 128, 128, 64) 73792       concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 128, 128, 64) 0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 128, 128, 64) 36928       dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 32) 8224        conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 256, 256, 64) 0           conv2d_transpose_7[0][0]         \n",
            "                                                                 conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 256, 256, 32) 18464       concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 256, 256, 32) 0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 256, 256, 32) 9248        dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 512, 512, 16) 2064        conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 512, 512, 32) 0           conv2d_transpose_8[0][0]         \n",
            "                                                                 conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 512, 512, 16) 4624        concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 512, 512, 16) 0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 512, 512, 16) 2320        dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 512, 512, 1)  17          conv2d_137[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,941,105\n",
            "Trainable params: 1,941,105\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-wbZ5wyQ56Zi",
        "colab_type": "code",
        "outputId": "bd5e3554-aa79-4a37-b1ef-5b017a3dda89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1564
        }
      },
      "cell_type": "code",
      "source": [
        "### A different U-Net implementation\n",
        "\n",
        "\n",
        "inputs = Input((H, W, C))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "n = 1 # can use this as a performance complexity lever\n",
        "\n",
        "c1 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "c1 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c1)\n",
        "p1 = MaxPooling2D(pool_size=(2, 2))(c1)\n",
        "\n",
        "c2 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p1)\n",
        "c2 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c2)\n",
        "p2 = MaxPooling2D(pool_size=(2, 2))(c2)\n",
        "\n",
        "c3 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p2)\n",
        "c3 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c3)\n",
        "p3 = MaxPooling2D(pool_size=(2, 2))(c3)\n",
        "\n",
        "c4 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p3)\n",
        "c4 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c4)\n",
        "d4 = Dropout(0.5)(c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2))(d4)\n",
        "\n",
        "c5 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p4)\n",
        "c5 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c5)\n",
        "d5 = Dropout(0.5)(c5)\n",
        "\n",
        "u6 = Conv2D(128, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(d5))\n",
        "m6 = concatenate([d4,u6], axis = 3)\n",
        "c6 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(m6)\n",
        "c6 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c6)\n",
        "\n",
        "u7 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(c6))\n",
        "m7 = concatenate([c3,u7], axis = 3)\n",
        "c7 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(m7)\n",
        "c7 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c7)\n",
        "\n",
        "u8 = Conv2D(64, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(c7))\n",
        "m8 = concatenate([c2,u8], axis = 3)\n",
        "c8 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(m8)\n",
        "c8 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c8)\n",
        "\n",
        "u9 = Conv2D(32, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(c8))\n",
        "m9 = concatenate([c1,u9], axis = 3)\n",
        "c9 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(m9)\n",
        "c9 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c9)\n",
        "c9 = Conv2D(2, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(c9)\n",
        "c10 = Conv2D(1, 1, activation = 'sigmoid')(c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c10)\n",
        "\n",
        "Model2 = Model(inputs=[inputs], outputs=[outputs])\n",
        "Model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
        "Model2.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 512, 512, 32) 896         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 512, 512, 32) 9248        conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 256, 256, 32) 0           conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 256, 256, 64) 18496       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 128, 128, 64) 0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 128, 128, 128 147584      conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 64, 64, 128)  0           conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64, 64, 256)  0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 32, 32, 256)  0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 512)  0           conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_13 (UpSampling2D) (None, 64, 64, 512)  0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 64, 64, 128)  262272      up_sampling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 64, 64, 384)  0           dropout_7[0][0]                  \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_14 (UpSampling2D) (None, 128, 128, 128 0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 128, 128, 128 147584      up_sampling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 128, 128, 256 0           conv2d_81[0][0]                  \n",
            "                                                                 conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 128, 128, 128 295040      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 128, 128, 128 147584      conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_15 (UpSampling2D) (None, 256, 256, 128 0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 256, 256, 128 0           conv2d_79[0][0]                  \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_16 (UpSampling2D) (None, 512, 512, 64) 0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 512, 512, 32) 8224        up_sampling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 512, 512, 64) 0           conv2d_77[0][0]                  \n",
            "                                                                 conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 512, 512, 32) 18464       concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 512, 512, 32) 9248        conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 512, 512, 2)  578         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 512, 512, 1)  3           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 512, 512, 1)  2           conv2d_99[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,334,855\n",
            "Trainable params: 6,334,855\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKMc8AVS56Zk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ImgNumsWithRoads = ImgNums"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I04nR68p56Zm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Generator for second model\n",
        "\n",
        "BatchSize = 10\n",
        "\n",
        "ImgNumsModel2WithRoads = list(set(ImgNums2) & set(ImgNumsWithRoads))\n",
        "ImgPathsModel2WithRoads = list(it.compress(ImgPaths, list(np.isin(np.array(ImgNums), ImgNumsModel2WithRoads))))\n",
        "\n",
        "Model2TrainPaths, Model2ValPaths = train_test_split(ImgPathsModel2WithRoads, test_size = Pv)\n",
        "\n",
        "Model2TrainGen = image_batch_generator(Model2TrainPaths, batchsize = BatchSize)\n",
        "Model2ValGen = image_batch_generator(Model2ValPaths, batchsize = BatchSize)\n",
        "\n",
        "Model2TrainSteps = calc_steps(len(Model2TrainPaths), BatchSize)\n",
        "Model2ValSteps = calc_steps(len(Model2ValPaths), BatchSize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2L_c7jm56Zn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__qk0Us-56Zp",
        "colab_type": "code",
        "outputId": "0b3d3503-fea7-4b10-83c5-08e45c0a194e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2513
        }
      },
      "cell_type": "code",
      "source": [
        "### Training Model 2\n",
        "\n",
        "earlystopper = EarlyStopping(patience = 3, verbose = 1)\n",
        "checkpointer = ModelCheckpoint('Term_Project_st41_eps2/Model2_v3.h5', verbose = 1, save_best_only = True)\n",
        "\n",
        "Model2Results = Model2.fit_generator(\n",
        "    \n",
        "    generator = Model2TrainGen,\n",
        "    steps_per_epoch = Model2TrainSteps,\n",
        "    epochs = 25,\n",
        "    validation_data = Model2ValGen,\n",
        "    validation_steps = Model2ValSteps,\n",
        "    verbose = 1,\n",
        "    callbacks=[earlystopper, checkpointer]\n",
        "    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "436/436 [==============================] - 538s 1s/step - loss: 0.1768 - dice_coef: 0.0010 - val_loss: 0.1548 - val_dice_coef: 2.4172e-14\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.15484, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 2/25\n",
            "436/436 [==============================] - 515s 1s/step - loss: 0.1563 - dice_coef: 8.0594e-04 - val_loss: 0.1456 - val_dice_coef: 1.1643e-04\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.15484 to 0.14563, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 3/25\n",
            "436/436 [==============================] - 521s 1s/step - loss: 0.1522 - dice_coef: 5.7716e-04 - val_loss: 0.1390 - val_dice_coef: 2.4172e-14\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.14563 to 0.13897, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 4/25\n",
            "436/436 [==============================] - 521s 1s/step - loss: 0.1432 - dice_coef: 0.0017 - val_loss: 0.1270 - val_dice_coef: 0.0509\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.13897 to 0.12704, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 5/25\n",
            "436/436 [==============================] - 522s 1s/step - loss: 0.1324 - dice_coef: 0.0403 - val_loss: 0.1199 - val_dice_coef: 0.1682\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.12704 to 0.11987, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 6/25\n",
            "436/436 [==============================] - 518s 1s/step - loss: 0.1256 - dice_coef: 0.0969 - val_loss: 0.1145 - val_dice_coef: 0.2427\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.11987 to 0.11450, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 7/25\n",
            "436/436 [==============================] - 520s 1s/step - loss: 0.1176 - dice_coef: 0.1602 - val_loss: 0.1096 - val_dice_coef: 0.3295\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.11450 to 0.10955, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 8/25\n",
            "436/436 [==============================] - 518s 1s/step - loss: 0.1040 - dice_coef: 0.2985 - val_loss: 0.0925 - val_dice_coef: 0.4501\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.10955 to 0.09246, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 9/25\n",
            "436/436 [==============================] - 519s 1s/step - loss: 0.0957 - dice_coef: 0.3822 - val_loss: 0.0885 - val_dice_coef: 0.4724\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.09246 to 0.08851, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 10/25\n",
            "436/436 [==============================] - 516s 1s/step - loss: 0.0889 - dice_coef: 0.4479 - val_loss: 0.0818 - val_dice_coef: 0.5237\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.08851 to 0.08180, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 11/25\n",
            "436/436 [==============================] - 514s 1s/step - loss: 0.0838 - dice_coef: 0.4909 - val_loss: 0.0803 - val_dice_coef: 0.5395\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.08180 to 0.08030, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 12/25\n",
            "436/436 [==============================] - 519s 1s/step - loss: 0.0791 - dice_coef: 0.5248 - val_loss: 0.0747 - val_dice_coef: 0.5559\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.08030 to 0.07472, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 13/25\n",
            "436/436 [==============================] - 516s 1s/step - loss: 0.0751 - dice_coef: 0.5555 - val_loss: 0.0702 - val_dice_coef: 0.5728\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.07472 to 0.07021, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 14/25\n",
            "436/436 [==============================] - 520s 1s/step - loss: 0.0722 - dice_coef: 0.5766 - val_loss: 0.0678 - val_dice_coef: 0.6052\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.07021 to 0.06782, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 15/25\n",
            "436/436 [==============================] - 521s 1s/step - loss: 0.0691 - dice_coef: 0.5973 - val_loss: 0.0684 - val_dice_coef: 0.6028\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.06782\n",
            "Epoch 16/25\n",
            "436/436 [==============================] - 523s 1s/step - loss: 0.0663 - dice_coef: 0.6156 - val_loss: 0.0664 - val_dice_coef: 0.6124\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.06782 to 0.06638, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 17/25\n",
            "436/436 [==============================] - 521s 1s/step - loss: 0.0638 - dice_coef: 0.6315 - val_loss: 0.0635 - val_dice_coef: 0.6304\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.06638 to 0.06349, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 18/25\n",
            "436/436 [==============================] - 529s 1s/step - loss: 0.0612 - dice_coef: 0.6484 - val_loss: 0.0636 - val_dice_coef: 0.6329\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.06349\n",
            "Epoch 19/25\n",
            "436/436 [==============================] - 528s 1s/step - loss: 0.0591 - dice_coef: 0.6613 - val_loss: 0.0623 - val_dice_coef: 0.6403\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.06349 to 0.06234, saving model to Term_Project_st41_eps2/Model2_v2.h5\n",
            "Epoch 20/25\n",
            "436/436 [==============================] - 523s 1s/step - loss: 0.0569 - dice_coef: 0.6749 - val_loss: 0.0635 - val_dice_coef: 0.6308\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.06234\n",
            "Epoch 21/25\n",
            " 10/436 [..............................] - ETA: 6:29 - loss: 0.0627 - dice_coef: 0.6828"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3cc730275686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel2ValSteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "t8LjzG9_56Zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5X5Y_sf856Zt",
        "colab_type": "code",
        "outputId": "55cc58fe-6207-40c8-8567-4f04a5c6e402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "! ls Term_Project_st41_eps2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " comp-540-spring-2019\t Model1_rf.sav\t\t    README.md\n",
            " EDA.ipynb\t\t Model2_diff.h5\t\t    submission_2019-03-29.csv\n",
            "'Keras Tutorial.ipynb'\t Model2_v2.h5\t\t    submission_2019-03-30.csv\n",
            " Keras_U-Net.ipynb\t model-comp540-project.h5   Untitled.ipynb\n",
            " Model1\t\t\t Pixel_By_Pixel.ipynb\t    utils.py\n",
            " Model1.h5\t\t __pycache__\t\t    utils.pyc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8dmgiRkH56Zx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('Term_Project_st41_eps2/Model2_v2.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCs32pOa56Zz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7jv0w1aC56Z2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHDErdB656Z3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "750XrDs856Z5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKQyhjYc56Z6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MpIjbXWJ56aG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijZtbeoY56aI",
        "colab_type": "code",
        "outputId": "f7e9d96d-9e18-459b-d1d8-377c4ef0b380",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "### Loading images\n",
        "\n",
        "path_to_train = 'comp-540-spring-2019/train'\n",
        "\n",
        "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
        "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
        "\n",
        "train_img_paths = glob.glob(glob_train_imgs)\n",
        "train_mask_paths = glob.glob(glob_train_masks)\n",
        "\n",
        "ig = image_gen(train_img_paths)\n",
        "train_pixels, train_masks = [], []\n",
        "neighborhoods = [1 << exponent for exponent in range(1, 9)]\n",
        "\n",
        "count = 0\n",
        "for image, mask in ig:\n",
        "    \n",
        "    temp_img = pd.DataFrame(np.array(image).reshape((img_width * img_height, 3)))\n",
        "    temp_img.columns = [\"R\", \"G\", \"B\"]\n",
        "    temp_img[\"Lightness\"] = (temp_img[[\"R\", \"G\", \"B\"]].max(axis = 1) + temp_img[[\"R\", \"G\", \"B\"]].max(axis = 1)) / 2\n",
        "    \n",
        "    for neighbor in neighborhoods:\n",
        "        temp_n = img.fromarray(np.uint8(image)).resize((neighbor, neighbor))\n",
        "        temp_n_low_res = temp_n.resize((img_width, img_height))\n",
        "        temp_n_mat = pd.DataFrame(list(temp_n_low_res.getdata()))\n",
        "        temp_n_mat.columns = [\"R\", \"G\", \"B\"]\n",
        "        temp_img[(\"R_\" + chr(neighbor))] = temp_n_mat[\"R\"]\n",
        "        temp_img[(\"G_\" + chr(neighbor))] = temp_n_mat[\"G\"]\n",
        "        temp_img[(\"B_\" + chr(neighbor))] = temp_n_mat[\"B\"]\n",
        "    \n",
        "    temp_img['Mask'] = np.array(mask).reshape((img_width * img_height))\n",
        "    temp_img = temp_img.sample(int((temp_img.shape[0]) * subset_proportion))\n",
        "    \n",
        "    train_masks.append(temp_img['Mask'])\n",
        "    train_pixels.append(temp_img.drop('Mask', axis = 1))\n",
        "    \n",
        "    if(count == batch_size):\n",
        "        break\n",
        "    count += 1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
            "/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 16s, sys: 7.96 s, total: 1min 24s\n",
            "Wall time: 47 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_WiAuk6756aU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_masks = np.array(np.concatenate(train_masks, axis = 0))[:, np.newaxis]\n",
        "train_pixels = np.concatenate(train_pixels, axis = 0)\n",
        "train_data = pd.DataFrame(np.concatenate([train_pixels, train_masks], axis = 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K81yDAaS56ab",
        "colab_type": "code",
        "outputId": "0c8f8eae-1066-45dc-cb11-31e19ff5e40a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Building features\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "cQp7BO1956am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YaPpx46P56ap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Splitting into train and validation\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(train_data[train_data.columns[0:28]], \\\n",
        "                                                    train_data[train_data.columns[28]], test_size = 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnazMUpZ56aq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Model for road detection in images with roads\n",
        "### Input: list of images which have been predicted to have roads\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 300, random_state = 123)\n",
        "\n",
        "rffit = rf.fit(train_X, train_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YNKpjk_O56at",
        "colab_type": "code",
        "outputId": "78bcfa62-c84e-4825-ce66-78f8a75227b5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Evaluation metrics\n",
        "\n",
        "pred_y = np.round(rf.predict(test_X))\n",
        "\n",
        "pred_y = np.round(pred_y)\n",
        "conf_mat = confusion_matrix(test_y, pred_y)\n",
        "print(conf_mat)\n",
        "print(classification_report(test_y, pred_y))\n",
        "print(1 - dice(pred_y, test_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[132612   1163]\n",
            " [  3194    655]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.98    133775\n",
            "         1.0       0.36      0.17      0.23      3849\n",
            "\n",
            "   micro avg       0.97      0.97      0.97    137624\n",
            "   macro avg       0.67      0.58      0.61    137624\n",
            "weighted avg       0.96      0.97      0.96    137624\n",
            "\n",
            "0.23116287277218983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6nK8YB6Y56az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Model for smoothing mask predictions\n",
        "### Input: list of masks"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}