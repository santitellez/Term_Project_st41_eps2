{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import itertools as it\n",
    "import cv2 as cv\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import feature\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "img_channels = 7\n",
    "# img_height = 512\n",
    "# img_width = 512\n",
    "# img_channels = 3\n",
    "\n",
    "path_to_train = 'comp-540-spring-2019/train'\n",
    "\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "\n",
    "train_img_paths = glob(glob_train_imgs)\n",
    "train_mask_paths = glob(glob_train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_id(img_path):\n",
    "    \n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "    return img_id\n",
    "\n",
    "def image_gen(img_paths, img_size=(img_height, img_width)):\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        img_id = get_img_id(img_path)\n",
    "        mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "        \n",
    "        img = imread(img_path) / 255.\n",
    "        mask = rgb2gray(imread(mask_path))\n",
    "        \n",
    "        img = resize(img, img_size, preserve_range=True)\n",
    "        mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
    "        mask = (mask >= 0.5).astype(float)\n",
    "        \n",
    "        ####\n",
    "        \n",
    "        # Adding the Canny layers\n",
    "        \n",
    "        img_gray = rgb2gray(img)\n",
    "        canny_sig2 = feature.canny(img_gray, sigma=2)\n",
    "        canny_sig3 = feature.canny(img_gray, sigma=3)\n",
    "        canny_sig4 = feature.canny(img_gray, sigma=4)\n",
    "        canny_sig5 = feature.canny(img_gray, sigma=5)\n",
    "        img = np.dstack((img, canny_sig2))\n",
    "        img = np.dstack((img, canny_sig3))\n",
    "        img = np.dstack((img, canny_sig4))\n",
    "        img = np.dstack((img, canny_sig5))\n",
    "        \n",
    "        ####\n",
    "        \n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliot/Library/Python/3.6/lib/python/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/elliot/Library/Python/3.6/lib/python/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ig = image_gen(train_img_paths)\n",
    "\n",
    "first_img, first_mask = next(ig)\n",
    "# second_img, second_mask = next(ig)\n",
    "# third_img, third_mask = next(ig)\n",
    "# fourth_img, fourth_mask = next(ig)\n",
    "# fifth_img, fifth_mask = next(ig)\n",
    "# sixth_img, sixth_mask = next(ig)\n",
    "# seventh_img, seventh_mask = next(ig)\n",
    "\n",
    "# plt.imshow(seventh_img)\n",
    "# plt.show()\n",
    "# plt.imshow(seventh_mask, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "test = first_img[:,:,3]\n",
    "\n",
    "plt.imshow(test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-9\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 7)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 7)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 16) 1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 256)    295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8, 8, 256)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 256)    590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 128)  131200      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 64)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 32)   8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 32)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 32)   9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 16) 2064        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 128, 16) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 16) 2320        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  17          conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,681\n",
      "Trainable params: 1,941,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generally, decrease (x,y) by factor 2 => Increase (z) by factor 2\n",
    "\n",
    "inputs = Input((img_height, img_width, img_channels))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "n = 1 # can use this as a performance complexity lever\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_batch_generator(img_paths, batchsize=batch_size):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ig = image_gen(img_paths)\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for img, mask in ig:\n",
    "\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(mask)\n",
    "\n",
    "            if len(batch_img) == batchsize:\n",
    "                \n",
    "                yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
    "                batch_img, batch_mask = [], []\n",
    "        \n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
    "            batch_img, batch_mask = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 7)\n",
      "(32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "traingen = image_batch_generator(train_img_paths, batchsize=batch_size)\n",
    "\n",
    "image, mask = next(traingen)\n",
    "print(image.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "239/239 [==============================] - 969s 4s/step - loss: 0.1762 - dice_coef: 0.0010 - val_loss: 0.1647 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16470, saving model to model-comp540-project.h5\n",
      "Epoch 2/50\n",
      "239/239 [==============================] - 906s 4s/step - loss: 0.1657 - dice_coef: 1.0360e-13 - val_loss: 0.1638 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16470 to 0.16384, saving model to model-comp540-project.h5\n",
      "Epoch 3/50\n",
      "239/239 [==============================] - 878s 4s/step - loss: 0.1647 - dice_coef: 1.0360e-13 - val_loss: 0.1570 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16384 to 0.15703, saving model to model-comp540-project.h5\n",
      "Epoch 4/50\n",
      "239/239 [==============================] - 875s 4s/step - loss: 0.1522 - dice_coef: 6.3679e-06 - val_loss: 0.1459 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15703 to 0.14588, saving model to model-comp540-project.h5\n",
      "Epoch 5/50\n",
      "239/239 [==============================] - 873s 4s/step - loss: 0.1483 - dice_coef: 1.0360e-13 - val_loss: 0.1432 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14588 to 0.14317, saving model to model-comp540-project.h5\n",
      "Epoch 6/50\n",
      "239/239 [==============================] - 870s 4s/step - loss: 0.1598 - dice_coef: 6.1509e-04 - val_loss: 0.6132 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14317\n",
      "Epoch 7/50\n",
      "239/239 [==============================] - 868s 4s/step - loss: 0.6256 - dice_coef: 1.0360e-13 - val_loss: 0.6132 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14317\n",
      "Epoch 8/50\n",
      "239/239 [==============================] - 864s 4s/step - loss: 0.6256 - dice_coef: 1.0360e-13 - val_loss: 0.6132 - val_dice_coef: 1.0571e-13\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14317\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=0.3)\n",
    "\n",
    "traingen = image_batch_generator(train_img_paths, batchsize=batch_size)\n",
    "valgen = image_batch_generator(val_img_paths, batchsize=batch_size)\n",
    "\n",
    "def calc_steps(data_len, batchsize):\n",
    "    \n",
    "    return (data_len + batchsize - 1) // batchsize\n",
    "\n",
    "train_steps = calc_steps(len(train_img_paths), batch_size)\n",
    "val_steps = calc_steps(len(val_img_paths), batch_size)\n",
    "\n",
    "\n",
    "\n",
    "earlystopper = EarlyStopping(patience=3, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-comp540-project.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "results = model.fit_generator(\n",
    "    \n",
    "    generator=traingen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=50,\n",
    "    validation_data=valgen,\n",
    "    validation_steps=val_steps,\n",
    "    verbose=1,\n",
    "    callbacks=[earlystopper, checkpointer]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "def create_submission(csv_name, predictions, image_ids):\n",
    "    \"\"\"\n",
    "    csv_name -> string for csv (\"XXXXXXX.csv\")\n",
    "    predictions -> numpyarray of size (num_examples, height, width)\n",
    "                In this case (num_examples, 512, 512)\n",
    "    image_ids -> numpyarray or list of size (num_examples,)\n",
    "    \n",
    "    predictions[i] should be the prediction of road for image_id[i]\n",
    "    \"\"\"\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ImageId'] = image_ids\n",
    "    encodings = []\n",
    "    num_images = len(image_ids)\n",
    "    for i in range(num_images):\n",
    "        if (i+1) % (num_images//10) == 0:\n",
    "            print(i, num_images)\n",
    "        encodings.append(rle_encoding(predictions[i]))\n",
    "        \n",
    "    sub['EncodedPixels'] = encodings\n",
    "    #sub['Height'] = [512]*num_images Nonger needed for DICE Scoring\n",
    "    #sub['Width'] = [512]*num_images Nonger needed for DICE Scoring\n",
    "    sub.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    \"\"\"\n",
    "    x = numpyarray of size (height, width) representing the mask of an image\n",
    "    if x[i,j] == 0:\n",
    "        image[i,j] is not a road pixel\n",
    "    if x[i,j] != 0:\n",
    "        image[i,j] is a road pixel\n",
    "    \"\"\"\n",
    "    dots = np.where(x.T.flatten() != 0)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): \n",
    "            run_lengths.extend((b+1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_gen(img_paths, img_size=(256, 256)):\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        img_id = get_img_id(img_path)\n",
    "        \n",
    "        img = imread(img_path) / 255.\n",
    "        \n",
    "        img = resize(img, img_size, preserve_range=True)\n",
    "        \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        yield img\n",
    "        \n",
    "def test_generator(img_paths, batchsize = batch_size):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ig = test_image_gen(img_paths)\n",
    "        batch_img = []\n",
    "        \n",
    "        for img in ig:\n",
    "\n",
    "            batch_img.append(img)\n",
    "\n",
    "            if len(batch_img) == batchsize:\n",
    "                \n",
    "                yield np.stack(batch_img, axis=0)\n",
    "                batch_img = []\n",
    "        \n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0)\n",
    "            batch_img = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Predictions\n",
    "\n",
    "best = load_model(\"model-comp540-project.h5\", custom_objects = {'dice_coef':dice_coef})\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "img_channels = 3\n",
    "\n",
    "path_to_test = 'comp-540-spring-2019/val'\n",
    "\n",
    "glob_test_imgs = os.path.join(path_to_test, '*_sat.jpg')\n",
    "test_img_paths = glob(glob_test_imgs)\n",
    "\n",
    "img_names = glob(\"comp-540-spring-2019/val/*.jpg\")\n",
    "img_numbers = [re.findall(r'/(\\d+)', img_name) for img_name in img_names]\n",
    "img_nums = list(it.chain.from_iterable(img_numbers))\n",
    "num_of_imgs = len(img_nums)\n",
    "\n",
    "submission = []\n",
    "img_ids = []\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in test_image_gen(test_img_paths):\n",
    "    \n",
    "    k = k + 1\n",
    "    \n",
    "    img = i\n",
    "    img = np.squeeze(img, axis=0)\n",
    "\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "    \n",
    "    img = i\n",
    "    pred = np.round(best.predict(img))\n",
    "    \n",
    "    pred = np.squeeze(pred, axis=(0, 3))\n",
    "    \n",
    "    pred = resize(pred, (512, 512), preserve_range=True)\n",
    "    \n",
    "    # plt.imshow(pred, cmap='gray')\n",
    "    # plt.show()\n",
    "    \n",
    "    submission.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215 2169\n",
      "431 2169\n",
      "647 2169\n",
      "863 2169\n",
      "1079 2169\n",
      "1295 2169\n",
      "1511 2169\n",
      "1727 2169\n",
      "1943 2169\n",
      "2159 2169\n"
     ]
    }
   ],
   "source": [
    "create_submission(\"submission_2019-03-29.csv\", np.array(submission), np.array(img_nums).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "\n",
    "keras.losses.loss = dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = load_model(\"model-comp540-project.h5\", custom_objects = {'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_gen(img_paths, img_size=(img_height, img_width)):\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        img_id = get_img_id(img_path)\n",
    "        \n",
    "        img = imread(img_path) / 255.\n",
    "        \n",
    "        img = resize(img, img_size, preserve_range=True)\n",
    "        \n",
    "        yield img\n",
    "\n",
    "def test_generator(img_paths, batchsize = batch_size):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ig = test_image_gen(img_paths)\n",
    "        batch_img = []\n",
    "        \n",
    "        for img in ig:\n",
    "\n",
    "            batch_img.append(img)\n",
    "\n",
    "            if len(batch_img) == batchsize:\n",
    "                \n",
    "                yield np.stack(batch_img, axis=0)\n",
    "                batch_img = []\n",
    "        \n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0)\n",
    "            batch_img = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_height = 512\n",
    "img_width = 512\n",
    "img_channels = 3\n",
    "\n",
    "path_to_test = 'comp-540-spring-2019/val'\n",
    "\n",
    "glob_test_imgs = os.path.join(path_to_test, '*_sat.jpg')\n",
    "\n",
    "test_img_paths = glob(glob_test_imgs)\n",
    "\n",
    "batch_size = len(test_img_paths)\n",
    "batch_size = 10\n",
    "\n",
    "testgen = test_generator(test_img_paths, batchsize = batch_size)\n",
    "\n",
    "predictions = best.predict_generator(testgen, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(csv_name, predictions, image_ids):\n",
    "    \"\"\"\n",
    "    csv_name -> string for csv (\"XXXXXXX.csv\")\n",
    "    predictions -> numpyarray of size (num_examples, height, width)\n",
    "                In this case (num_examples, 512, 512)\n",
    "    image_ids -> numpyarray or list of size (num_examples,)\n",
    "    \n",
    "    predictions[i] should be the prediciton of road for image_id[i]\n",
    "    \"\"\"\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ImageId'] = image_ids\n",
    "    encodings = []\n",
    "    num_images = len(image_ids)\n",
    "    for i in range(num_images):\n",
    "        if (i+1) % (num_images//10) == 0:\n",
    "            print(i, num_images)\n",
    "        encodings.append(rle_encoding(predictions[i]))\n",
    "        \n",
    "    sub['EncodedPixels'] = encodings\n",
    "    sub.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 128, 128, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
