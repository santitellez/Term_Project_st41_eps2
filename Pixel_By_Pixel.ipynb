{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import itertools as it\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from PIL import Image as ig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from utils import create_submission, rle_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "\n",
    "def get_img_id(img_path):\n",
    "    \n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "    return img_id\n",
    "\n",
    "def image_gen(img_paths, img_size=(img_height, img_width)):\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        img_id = get_img_id(img_path)\n",
    "        mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "        \n",
    "        img = imread(img_path) / 255.\n",
    "        mask = rgb2gray(imread(mask_path))\n",
    "        \n",
    "        img = resize(img, img_size, preserve_range=True)\n",
    "        mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
    "        mask = (mask >= 0.5).astype(float)\n",
    "        \n",
    "        yield img, mask\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def image_batch_generator(img_paths, batchsize = batch_size):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ig = image_gen(img_paths)\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for img, mask in ig:\n",
    "\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(mask)\n",
    "\n",
    "            if len(batch_img) == batchsize:\n",
    "                \n",
    "                yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
    "                batch_img, batch_mask = [], []\n",
    "        \n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
    "            batch_img, batch_mask = [], []\n",
    "\n",
    "def calc_steps(data_len, batchsize):\n",
    "    \n",
    "    return (data_len + batchsize - 1) // batchsize\n",
    "\n",
    "def create_submission(csv_name, predictions, image_ids):\n",
    "    \"\"\"\n",
    "    csv_name -> string for csv (\"XXXXXXX.csv\")\n",
    "    predictions -> numpyarray of size (num_examples, height, width)\n",
    "                In this case (num_examples, 512, 512)\n",
    "    image_ids -> numpyarray or list of size (num_examples,)\n",
    "    \n",
    "    predictions[i] should be the prediciton of road for image_id[i]\n",
    "    \"\"\"\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ImageId'] = image_ids\n",
    "    encodings = []\n",
    "    num_images = len(image_ids)\n",
    "    for i in range(num_images):\n",
    "        if (i+1) % (num_images//10) == 0:\n",
    "            print(i, num_images)\n",
    "        encodings.append(rle_encoding(predictions[i]))\n",
    "        \n",
    "    sub['EncodedPixels'] = encodings\n",
    "    sub.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Pipeline Parameters\n",
    "\n",
    "ImgPaths = glob.glob(\"comp-540-spring-2019/train/*.jpg\")\n",
    "ImgNums = [re.findall(r'/(\\d+)', path)[0] for path in ImgPaths]\n",
    "\n",
    "M = len(glob.glob(\"comp-540-spring-2019/train/*.jpg\")) # Number of training images\n",
    "H = 512 # Image height\n",
    "W = 512 # Image width\n",
    "C = 3 # Channels R, G, B\n",
    "\n",
    "Pt = .8 # Train proportion\n",
    "Pv = .2 # Validation proportion\n",
    "P1 = .25 # Proportion of data used in Model 1\n",
    "P2 = .5 # Proportion of data used in Model 2\n",
    "P3 = 1 - P1 - P2 # Proportion of data used in Model 3\n",
    "\n",
    "# Subsetting images for training and validation\n",
    "\n",
    "random.seed(1)\n",
    "RandomOrder = np.random.choice(ImgNums, M)\n",
    "\n",
    "ImgNums1 = RandomOrder[:int(M * P1)] # Model 1 images\n",
    "ImgNums2 = RandomOrder[int(M * P1):int(M * (P1 + P2))] # Model 2 images\n",
    "ImgNums3 = RandomOrder[int(M * (P1 + P2)):] # Model 3 images\n",
    "\n",
    "BatchSize = 20\n",
    "\n",
    "Smooth = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature engineering Model 1\n",
    "\n",
    "def Model1FeatureEngineering(imgnums, train_or_val = \"train\"):\n",
    "    Data = []\n",
    "\n",
    "    for num in imgnums:\n",
    "        img = ig.open(\"comp-540-spring-2019/\" + train_or_val + \"/\" + num + \"_sat.jpg\")\n",
    "        if train_or_val == \"train\":\n",
    "            msk = ig.open(\"comp-540-spring-2019/\" + train_or_val + \"/\" + num + \"_msk.png\")\n",
    "        img_mat = np.array(img.getdata())\n",
    "        img_avg = np.mean(img_mat, axis = 0)\n",
    "        img_med = np.median(img_mat, axis = 0)\n",
    "        img_var = np.var(img_mat, axis = 0)\n",
    "        img_min = np.amin(img_mat, axis = 0)\n",
    "        img_max = np.amax(img_mat, axis = 0)\n",
    "        img_ran = np.ptp(img_mat, axis = 0)\n",
    "        img_25q = np.percentile(img_mat, axis = 0, q = 25)\n",
    "        img_75q = np.percentile(img_mat, axis = 0, q = 75)\n",
    "        if train_or_val == \"train\":\n",
    "            y = [(np.sum(np.array(msk.getdata())) > 0) * 1]\n",
    "\n",
    "            img_data = np.concatenate((img_avg, img_med, img_var, img_min, img_max, img_ran, img_25q, img_75q, y))\n",
    "        if train_or_val == \"val\":\n",
    "            img_data = np.concatenate((img_avg, img_med, img_var, img_min, img_max, img_ran, img_25q, img_75q))\n",
    "        Data.append(img_data)\n",
    "\n",
    "    Data = np.array(Data)\n",
    "    return(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40  60]\n",
      " [ 15 430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.40      0.52       100\n",
      "         1.0       0.88      0.97      0.92       445\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       545\n",
      "   macro avg       0.80      0.68      0.72       545\n",
      "weighted avg       0.85      0.86      0.85       545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Model for predicting whether image has any roads\n",
    "\n",
    "Data = Model1FeatureEngineering(ImgNums1, \"train\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(Data[:, :(Data.shape[1] - 1)], Data[:, (Data.shape[1] - 1)], train_size = Pt)\n",
    "\n",
    "ntrees = [50]\n",
    "mtrys = [2]\n",
    "max_depth = [35]\n",
    "\n",
    "results = {}\n",
    "best_val_acc = 0\n",
    "\n",
    "for nt in ntrees:\n",
    "    for mt in mtrys:\n",
    "        for md in max_depth:\n",
    "            any_roads_model = RandomForestClassifier(n_estimators = nt, max_depth = md, min_samples_split = mt)\n",
    "            any_roads_model_fit = any_roads_model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = np.round(any_roads_model.predict(X_val))\n",
    "            y_pred = np.round(y_pred)\n",
    "            val_acc = np.sum(y_pred == y_val) / y_val.shape[0]\n",
    "            \n",
    "            results[(nt, mt, md)] = val_acc\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_model = any_roads_model\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "y_pred = np.round(best_model.predict(X_val))\n",
    "\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "print(conf_mat)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save best Model 1\n",
    "\n",
    "best_model1 = joblib.dump(best_model, \"Model1.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 549  883]\n",
      " [ 250 6491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.38      0.49      1432\n",
      "         1.0       0.88      0.96      0.92      6741\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      8173\n",
      "   macro avg       0.78      0.67      0.71      8173\n",
      "weighted avg       0.85      0.86      0.84      8173\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-0a54056072ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_actual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mImgNumsWithRoads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mImgNums23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "### Model 1 feature engineering for Model 2\n",
    "\n",
    "ImgNums23 = np.concatenate((ImgNums2, ImgNums3))\n",
    "Data =  Model1FeatureEngineering(ImgNums23, \"train\")\n",
    "\n",
    "y_actual = Data[:, (Data.shape[1] - 1)]\n",
    "Data = Data[:, :(Data.shape[1] - 1)]\n",
    "\n",
    "y_pred = np.round(best_model.predict(Data))\n",
    "\n",
    "conf_mat = confusion_matrix(y_actual, y_pred)\n",
    "print(conf_mat)\n",
    "print(classification_report(y_actual, y_pred))\n",
    "\n",
    "ImgNumsWithRoads = ImgNums23[(y_pred == 1)]\n",
    "ImgNumsWithoutRoads = ImgNums23[(y_pred != 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['9401', '31444', '40130', ..., '35129', '4482', '22937'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Making blank masks for no-road images\n",
    "\n",
    "ImgNums2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 7.96 s, total: 1min 24s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Loading images\n",
    "\n",
    "path_to_train = 'comp-540-spring-2019/train'\n",
    "\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "\n",
    "train_img_paths = glob.glob(glob_train_imgs)\n",
    "train_mask_paths = glob.glob(glob_train_masks)\n",
    "\n",
    "ig = image_gen(train_img_paths)\n",
    "train_pixels, train_masks = [], []\n",
    "neighborhoods = [1 << exponent for exponent in range(1, 9)]\n",
    "\n",
    "count = 0\n",
    "for image, mask in ig:\n",
    "    \n",
    "    temp_img = pd.DataFrame(np.array(image).reshape((img_width * img_height, 3)))\n",
    "    temp_img.columns = [\"R\", \"G\", \"B\"]\n",
    "    temp_img[\"Lightness\"] = (temp_img[[\"R\", \"G\", \"B\"]].max(axis = 1) + temp_img[[\"R\", \"G\", \"B\"]].max(axis = 1)) / 2\n",
    "    \n",
    "    for neighbor in neighborhoods:\n",
    "        temp_n = img.fromarray(np.uint8(image)).resize((neighbor, neighbor))\n",
    "        temp_n_low_res = temp_n.resize((img_width, img_height))\n",
    "        temp_n_mat = pd.DataFrame(list(temp_n_low_res.getdata()))\n",
    "        temp_n_mat.columns = [\"R\", \"G\", \"B\"]\n",
    "        temp_img[(\"R_\" + chr(neighbor))] = temp_n_mat[\"R\"]\n",
    "        temp_img[(\"G_\" + chr(neighbor))] = temp_n_mat[\"G\"]\n",
    "        temp_img[(\"B_\" + chr(neighbor))] = temp_n_mat[\"B\"]\n",
    "    \n",
    "    temp_img['Mask'] = np.array(mask).reshape((img_width * img_height))\n",
    "    temp_img = temp_img.sample(int((temp_img.shape[0]) * subset_proportion))\n",
    "    \n",
    "    train_masks.append(temp_img['Mask'])\n",
    "    train_pixels.append(temp_img.drop('Mask', axis = 1))\n",
    "    \n",
    "    if(count == batch_size):\n",
    "        break\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = np.array(np.concatenate(train_masks, axis = 0))[:, np.newaxis]\n",
    "train_pixels = np.concatenate(train_pixels, axis = 0)\n",
    "train_data = pd.DataFrame(np.concatenate([train_pixels, train_masks], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Building features\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting into train and validation\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_data[train_data.columns[0:28]], \\\n",
    "                                                    train_data[train_data.columns[28]], test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model for road detection in images with roads\n",
    "### Input: list of images which have been predicted to have roads\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 300, random_state = 123)\n",
    "\n",
    "rffit = rf.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132612   1163]\n",
      " [  3194    655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98    133775\n",
      "         1.0       0.36      0.17      0.23      3849\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    137624\n",
      "   macro avg       0.67      0.58      0.61    137624\n",
      "weighted avg       0.96      0.97      0.96    137624\n",
      "\n",
      "0.23116287277218983\n"
     ]
    }
   ],
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "pred_y = np.round(rf.predict(test_X))\n",
    "\n",
    "pred_y = np.round(pred_y)\n",
    "conf_mat = confusion_matrix(test_y, pred_y)\n",
    "print(conf_mat)\n",
    "print(classification_report(test_y, pred_y))\n",
    "print(1 - dice(pred_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model for smoothing mask predictions\n",
    "### Input: list of masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
