{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import re\n",
    "import os\n",
    "import itertools as it\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from PIL import Image as img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from utils import create_submission, rle_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "\n",
    "subset_proportion = .05\n",
    "batch_size = 20\n",
    "\n",
    "img_height = 512\n",
    "img_width = 512\n",
    "img_channels = 3\n",
    "smooth = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "\n",
    "def get_img_id(img_path):\n",
    "    \n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "    return img_id\n",
    "\n",
    "def image_gen(img_paths, img_size=(img_height, img_width)):\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        img_id = get_img_id(img_path)\n",
    "        mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "        \n",
    "        img = imread(img_path) / 255.\n",
    "        mask = rgb2gray(imread(mask_path))\n",
    "        \n",
    "        img = resize(img, img_size, preserve_range=True)\n",
    "        mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
    "        mask = (mask >= 0.5).astype(float)\n",
    "        \n",
    "        yield img, mask\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def image_batch_generator(img_paths, batchsize=batch_size):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ig = image_gen(img_paths)\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for img, mask in ig:\n",
    "\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(mask)\n",
    "\n",
    "            if len(batch_img) == batchsize:\n",
    "                \n",
    "                yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
    "                batch_img, batch_mask = [], []\n",
    "        \n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0), np.expand_dims(np.stack(batch_mask, axis=0),axis = -1)\n",
    "            batch_img, batch_mask = [], []\n",
    "\n",
    "def calc_steps(data_len, batchsize):\n",
    "    \n",
    "    return (data_len + batchsize - 1) // batchsize\n",
    "\n",
    "def create_submission(csv_name, predictions, image_ids):\n",
    "    \"\"\"\n",
    "    csv_name -> string for csv (\"XXXXXXX.csv\")\n",
    "    predictions -> numpyarray of size (num_examples, height, width)\n",
    "                In this case (num_examples, 512, 512)\n",
    "    image_ids -> numpyarray or list of size (num_examples,)\n",
    "    \n",
    "    predictions[i] should be the prediciton of road for image_id[i]\n",
    "    \"\"\"\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ImageId'] = image_ids\n",
    "    encodings = []\n",
    "    num_images = len(image_ids)\n",
    "    for i in range(num_images):\n",
    "        if (i+1) % (num_images//10) == 0:\n",
    "            print(i, num_images)\n",
    "        encodings.append(rle_encoding(predictions[i]))\n",
    "        \n",
    "    sub['EncodedPixels'] = encodings\n",
    "    sub.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/envs/r-tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 7.96 s, total: 1min 24s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Loading images\n",
    "\n",
    "path_to_train = 'comp-540-spring-2019/train'\n",
    "\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "\n",
    "train_img_paths = glob.glob(glob_train_imgs)\n",
    "train_mask_paths = glob.glob(glob_train_masks)\n",
    "\n",
    "ig = image_gen(train_img_paths)\n",
    "train_pixels, train_masks = [], []\n",
    "neighborhoods = [1 << exponent for exponent in range(1, 9)]\n",
    "\n",
    "count = 0\n",
    "for image, mask in ig:\n",
    "    \n",
    "    temp_img = pd.DataFrame(np.array(image).reshape((img_width * img_height, 3)))\n",
    "    temp_img.columns = [\"R\", \"G\", \"B\"]\n",
    "    temp_img[\"Lightness\"] = (temp_img[[\"R\", \"G\", \"B\"]].max(axis = 1) + temp_img[[\"R\", \"G\", \"B\"]].max(axis = 1)) / 2\n",
    "    \n",
    "    for neighbor in neighborhoods:\n",
    "        temp_n = img.fromarray(np.uint8(image)).resize((neighbor, neighbor))\n",
    "        temp_n_low_res = temp_n.resize((img_width, img_height))\n",
    "        temp_n_mat = pd.DataFrame(list(temp_n_low_res.getdata()))\n",
    "        temp_n_mat.columns = [\"R\", \"G\", \"B\"]\n",
    "        temp_img[(\"R_\" + chr(neighbor))] = temp_n_mat[\"R\"]\n",
    "        temp_img[(\"G_\" + chr(neighbor))] = temp_n_mat[\"G\"]\n",
    "        temp_img[(\"B_\" + chr(neighbor))] = temp_n_mat[\"B\"]\n",
    "    \n",
    "    temp_img['Mask'] = np.array(mask).reshape((img_width * img_height))\n",
    "    temp_img = temp_img.sample(int((temp_img.shape[0]) * subset_proportion))\n",
    "    \n",
    "    train_masks.append(temp_img['Mask'])\n",
    "    train_pixels.append(temp_img.drop('Mask', axis = 1))\n",
    "    \n",
    "    if(count == batch_size):\n",
    "        break\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = np.array(np.concatenate(train_masks, axis = 0))[:, np.newaxis]\n",
    "train_pixels = np.concatenate(train_pixels, axis = 0)\n",
    "train_data = pd.DataFrame(np.concatenate([train_pixels, train_masks], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Building features\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model for predicting whether image has any roads\n",
    "### Input: list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting into train and validation\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_data[train_data.columns[0:28]], \\\n",
    "                                                    train_data[train_data.columns[28]], test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model for road detection in images with roads\n",
    "### Input: list of images which have been predicted to have roads\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 300, random_state = 123)\n",
    "\n",
    "rffit = rf.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132612   1163]\n",
      " [  3194    655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98    133775\n",
      "         1.0       0.36      0.17      0.23      3849\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    137624\n",
      "   macro avg       0.67      0.58      0.61    137624\n",
      "weighted avg       0.96      0.97      0.96    137624\n",
      "\n",
      "0.23116287277218983\n"
     ]
    }
   ],
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "pred_y = np.round(rf.predict(test_X))\n",
    "\n",
    "pred_y = np.round(pred_y)\n",
    "conf_mat = confusion_matrix(test_y, pred_y)\n",
    "print(conf_mat)\n",
    "print(classification_report(test_y, pred_y))\n",
    "print(1 - dice(pred_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model for smoothing mask predictions\n",
    "### Input: list of masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
